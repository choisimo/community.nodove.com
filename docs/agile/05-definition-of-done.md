# 완료 정의 및 수락 기준 템플릿 (Definition of Done & Acceptance Criteria Template)

## 1. 완료 정의 (Definition of Done)

### 1.1 전체 프로젝트 완료 정의

완료 정의는 모든 팀원이 공통으로 이해하는 "완료"의 기준입니다. 모든 사용자 스토리와 작업은 아래 기준을 만족해야 완료로 간주됩니다.

#### 기능 개발 완료 기준
- [ ] **요구사항 구현**: 모든 수락 기준(AC) 100% 충족
- [ ] **코드 품질**: 코딩 표준 및 아키텍처 가이드라인 준수
- [ ] **코드 리뷰**: 최소 1명 이상의 동료 검토 완료 및 승인
- [ ] **단위 테스트**: 테스트 커버리지 최소 80% 달성
- [ ] **통합 테스트**: 관련 시스템과의 연동 테스트 통과
- [ ] **문서화**: 기술 문서 및 사용자 가이드 업데이트

#### 품질 보증 완료 기준
- [ ] **기능 테스트**: 모든 기능이 설계대로 동작함을 확인
- [ ] **회귀 테스트**: 기존 기능에 영향 없음을 확인
- [ ] **성능 테스트**: 성능 요구사항 충족 (페이지 로딩 3초 이하)
- [ ] **보안 테스트**: 보안 취약점 검사 및 해결
- [ ] **접근성 테스트**: WCAG 2.1 AA 수준 준수
- [ ] **크로스 플랫폼**: iOS, Android, Web에서 동일한 기능 동작

#### UI/UX 완료 기준
- [ ] **디자인 일치**: 승인된 디자인 100% 구현
- [ ] **반응형 디자인**: 다양한 화면 크기에서 적절한 표시
- [ ] **사용성 테스트**: 타겟 사용자의 태스크 완료율 90% 이상
- [ ] **로딩 상태**: 모든 비동기 작업에 적절한 로딩 표시
- [ ] **에러 처리**: 사용자 친화적인 에러 메시지 및 복구 방안 제공

#### 배포 완료 기준
- [ ] **스테이징 배포**: 스테이징 환경에서 완전한 기능 검증
- [ ] **배포 스크립트**: 자동화된 배포 프로세스로 배포 가능
- [ ] **모니터링**: 프로덕션 모니터링 및 알림 설정 완료
- [ ] **롤백 계획**: 문제 발생 시 즉시 롤백 가능한 상태
- [ ] **운영 문서**: 배포 및 운영 가이드 업데이트

### 1.2 AI 기능 전용 완료 기준

AI 기능의 특수성을 고려한 추가 완료 기준:

- [ ] **AI 응답 품질**: AI 기능의 정확도 및 유용성 검증
- [ ] **비용 모니터링**: AI API 사용량 및 비용 추적 시스템 구축
- [ ] **사용량 제한**: 사용자별 AI 기능 사용량 제한 및 관리
- [ ] **대체 시나리오**: AI 서비스 장애 시 대체 기능 제공
- [ ] **사용자 피드백**: AI 기능에 대한 사용자 만족도 수집 메커니즘

## 2. 수락 기준 템플릿 (Acceptance Criteria Template)

### 2.1 기본 수락 기준 작성 가이드

#### Given-When-Then 형식
```
Given [초기 상황/조건]
When [사용자 행동/이벤트]
Then [예상 결과/검증 기준]
```

#### 체크리스트 형식
각 기능별로 반드시 확인해야 할 항목들을 체크리스트로 작성

### 2.2 사용자 스토리별 수락 기준 예시

#### 예시 1: 사용자 회원가입 (US-001)
**사용자 스토리**: "사용자로서 이메일과 비밀번호로 회원가입할 수 있다"

**수락 기준**:

**기능 요구사항**:
- [ ] Given 회원가입 페이지에 접근한 사용자가
  When 올바른 이메일 형식과 비밀번호를 입력하고 가입 버튼을 클릭하면
  Then 계정이 생성되고 프로필 설정 페이지로 이동한다

- [ ] Given 이미 가입된 이메일로
  When 회원가입을 시도하면
  Then "이미 가입된 이메일입니다" 에러 메시지가 표시된다

- [ ] Given 잘못된 이메일 형식으로
  When 회원가입을 시도하면
  Then "올바른 이메일 형식을 입력해주세요" 에러 메시지가 표시된다

**비기능 요구사항**:
- [ ] 비밀번호는 최소 8자 이상, 영문+숫자+특수문자 조합 필수
- [ ] 회원가입 처리 시간은 3초 이내
- [ ] 모든 입력 데이터는 서버에서 재검증
- [ ] 비밀번호는 해시화되어 저장

**UI/UX 요구사항**:
- [ ] 입력 필드 유효성 검사는 실시간으로 표시
- [ ] 가입 진행 중 로딩 스피너 표시
- [ ] 성공/실패 메시지는 3초간 표시 후 자동 숨김
- [ ] 키보드 네비게이션 지원 (Tab 키로 이동)

#### 예시 2: AI 제목 제안 기능 (US-023)
**사용자 스토리**: "사용자로서 AI 도우미가 제안하는 제목을 받을 수 있다"

**수락 기준**:

**기능 요구사항**:
- [ ] Given 게시물 내용을 50자 이상 입력한 사용자가
  When 제목 입력 필드 옆의 "💡" 아이콘을 클릭하면
  Then AI가 분석한 3개의 제목 제안이 표시된다

- [ ] Given AI 제목 제안이 표시된 상황에서
  When 사용자가 제안된 제목 중 하나를 클릭하면
  Then 해당 제목이 제목 입력 필드에 자동으로 입력된다

- [ ] Given AI 서비스가 일시적으로 사용 불가능한 상황에서
  When 제목 제안을 요청하면
  Then "AI 서비스가 일시적으로 사용할 수 없습니다" 메시지와 함께 수동 입력 옵션을 제공한다

**AI 특화 요구사항**:
- [ ] AI 제안 생성 시간은 5초 이내
- [ ] 제안된 제목은 20-50자 길이 범위
- [ ] 제안된 제목은 서로 다른 스타일/톤으로 구성
- [ ] 사용자의 이전 글쓰기 패턴을 학습하여 개인화된 제안 제공

**사용량 제한**:
- [ ] 무료 사용자는 하루 3회까지 제목 제안 가능
- [ ] 유료 사용자는 하루 30회까지 제목 제안 가능
- [ ] 사용량 초과 시 적절한 안내 메시지 표시

**품질 기준**:
- [ ] 제안된 제목의 언어는 게시물 내용 언어와 일치
- [ ] 부적절한 내용이 포함된 제목은 필터링됨
- [ ] 제안 품질에 대한 사용자 피드백 수집 (👍/👎)

### 2.3 통합 테스트 수락 기준

#### End-to-End 시나리오
**시나리오**: 새 사용자의 첫 게시물 작성 완전한 플로우

**수락 기준**:
- [ ] 사용자가 회원가입부터 첫 게시물 발행까지 중단 없이 진행 가능
- [ ] AI 기능들이 순차적으로 올바르게 동작 (제목 제안 → 태그 생성 → 카테고리 추천)
- [ ] 발행된 게시물이 피드에 즉시 반영
- [ ] 전체 과정이 5분 이내 완료 가능
- [ ] 각 단계별 진행 상황이 사용자에게 명확히 전달

## 3. 테스트 케이스 템플릿

### 3.1 기능 테스트 케이스

#### 테스트 케이스 ID: TC-[기능코드]-[순번]
```
제목: [테스트 케이스 제목]
설명: [테스트 목적 및 범위]
전제조건: [테스트 실행 전 필요한 상태]
테스트 단계:
1. [단계별 실행 내용]
2. [단계별 실행 내용]
예상 결과: [기대하는 결과]
실제 결과: [테스트 실행 후 기록]
상태: [Pass/Fail/Blocked]
```

### 3.2 성능 테스트 케이스

#### 응답 시간 테스트
- **목표**: API 응답 시간 500ms 이하
- **방법**: 100명 동시 사용자 시뮬레이션
- **측정 항목**: 평균/최대/95% 응답 시간
- **통과 기준**: 95% 요청이 500ms 이내 응답

#### 부하 테스트
- **목표**: 1000명 동시 사용자 처리
- **방법**: 점진적 사용자 증가 테스트
- **측정 항목**: TPS, 에러율, 자원 사용률
- **통과 기준**: 에러율 1% 이하, CPU 사용률 80% 이하

### 3.3 보안 테스트 케이스

#### 인증/인가 테스트
- [ ] 비로그인 사용자의 보호된 리소스 접근 차단
- [ ] 권한 없는 사용자의 관리 기능 접근 차단
- [ ] JWT 토큰 만료 시 적절한 처리
- [ ] 세션 하이재킹 방지

#### 입력 검증 테스트
- [ ] SQL Injection 공격 차단
- [ ] XSS 공격 차단
- [ ] 파일 업로드 보안 검증
- [ ] API 파라미터 검증

## 4. 품질 측정 지표

### 4.1 개발 품질 지표
- **코드 커버리지**: 80% 이상
- **코드 복잡도**: Cyclomatic Complexity 10 이하
- **중복 코드**: 5% 이하
- **코드 리뷰 커버리지**: 100%

### 4.2 제품 품질 지표
- **버그 밀도**: 1000 LOC당 5개 이하
- **사용자 만족도**: 4.0/5.0 이상
- **성능 만족도**: 응답시간 목표 달성률 95% 이상
- **가용성**: 99.5% 이상

### 4.3 AI 기능 품질 지표
- **AI 제안 채택률**: 50% 이상
- **AI 응답 정확도**: 85% 이상 (사용자 피드백 기준)
- **AI 서비스 가용성**: 99% 이상
- **AI 응답 시간**: 5초 이내

## 5. 검토 및 승인 프로세스

### 5.1 수락 기준 검토 절차
1. **작성**: 프로덕트 오너가 초안 작성
2. **검토**: 개발팀과 QA 팀이 기술적 검토
3. **수정**: 피드백 반영 및 수정
4. **승인**: 모든 이해관계자 승인
5. **확정**: 스프린트 백로그에 반영

### 5.2 완료 기준 업데이트
- **주기**: 매 스프린트 회고 후
- **기준**: 발견된 이슈 및 개선사항 반영
- **승인**: 팀 전체 합의

## 6. 도구 및 체크리스트

### 6.1 개발 도구 체크리스트
- [ ] IDE 설정: 코딩 표준 자동 검사
- [ ] Git 훅: 커밋 전 테스트 자동 실행
- [ ] CI/CD: 빌드 및 테스트 자동화
- [ ] 코드 분석: SonarQube 등 정적 분석 도구

### 6.2 테스트 도구 체크리스트
- [ ] 단위 테스트: Jest, Flutter Test
- [ ] 통합 테스트: Postman, REST Assured
- [ ] UI 테스트: Selenium, Flutter Driver
- [ ] 성능 테스트: JMeter, Artillery

### 6.3 품질 관리 도구
- [ ] 이슈 추적: Jira, GitHub Issues
- [ ] 코드 리뷰: GitHub PR, GitLab MR
- [ ] 문서화: Confluence, Notion
- [ ] 모니터링: Sentry, Firebase Analytics

---

## 템플릿 활용 가이드

### 사용 방법
1. **프로젝트 초기**: 전체 완료 정의 팀 합의
2. **스토리 작성**: 각 사용자 스토리별 수락 기준 작성
3. **개발 중**: 체크리스트 기반 진행 상황 추적
4. **테스트 단계**: 테스트 케이스 기반 검증
5. **완료 판정**: 모든 기준 충족 확인

### 주의사항
- 수락 기준은 구체적이고 측정 가능해야 함
- 모든 팀원이 이해할 수 있는 명확한 언어 사용
- 비기능 요구사항도 반드시 포함
- 정기적인 검토 및 업데이트 필요

---

**문서 버전**: 1.0  
**작성일**: 2024년 1월  
**검토 주기**: 스프린트마다  
**업데이트**: 프로젝트 진행에 따라 지속 개선